{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "I will be leveraging the Paris Olympics aritcle from wikipedia to ask questions about about the 2024 Paris Olympics. I selected it for its recency and for the fact that many details around the olymnpics were known prior to 2021, but others would only be revealed after the event. This provided an opportunity to ask a question that might have been known, mainly, who provided surface-to-air missle protection for the olypics. This was likely setup years in advance, but may not have been reported on as early as 2021. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbabfe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dateutil.parser import parse\n",
    "import pandas as pd\n",
    "import requests\n",
    "from scipy.spatial.distance import cosine\n",
    "from typing import Union, List, Optional, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88bbd8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add embeddings to DataFrame and save to CSV\n",
    "embedding_model = \"text-embedding-3-small\" \n",
    "completion_model = 'gpt-3.5-turbo'\n",
    "batch_size = 25\n",
    "csv_w_embeddings = './wikipedia_embeddings.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "TODO: In the cells below, load your chosen dataset into a `pandas` dataframe with a column named `\"text\"`. This column should contain all of your text data, separated into at least 20 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c69b83a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get the Wikipedia page for \"2022\" since OpenAI's models stop in 2021\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://en.wikipedia.org/w/api.php?action=query&prop=extracts&exlimit=1&titles=2024_Summer_Olympics&explaintext=1&formatversion=2&format=json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load page text into a dataframe\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "# Get the Wikipedia page for \"2022\" since OpenAI's models stop in 2021\n",
    "resp = requests.get(\"https://en.wikipedia.org/w/api.php?action=query&prop=extracts&exlimit=1&titles=2024_Summer_Olympics&explaintext=1&formatversion=2&format=json\")\n",
    "\n",
    "# Load page text into a dataframe\n",
    "df = pd.DataFrame()\n",
    "df[\"text\"] = resp.json()[\"query\"][\"pages\"][0][\"extract\"].split(\"\\n\")\n",
    "\n",
    "# Clean up text to remove empty lines and headings\n",
    "df = df[(df[\"text\"].str.len() > 0) & (~df[\"text\"].str.startswith(\"==\"))]\n",
    "\n",
    "# text sample; adjust so dated text samples start with dates\n",
    "prefix = \"\"\n",
    "for (i, row) in df.iterrows():\n",
    "    # If the row already has \" - \", it already has the needed date prefix\n",
    "    if \" – \" not in row[\"text\"]:\n",
    "        try:\n",
    "            # If the row's text is a date, set it as the new prefix\n",
    "            parse(row[\"text\"])\n",
    "            prefix = row[\"text\"]\n",
    "        except:\n",
    "            # If the row's text isn't a date, add the prefix\n",
    "            row[\"text\"] = prefix + \" – \" + row[\"text\"]\n",
    "df = df[df[\"text\"].str.contains(\" – \")]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Custom Embeddings Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client\n",
    "from config import OPENAI_API_KEY\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get embeddings from OpenAI API\n",
    "def get_embeddings(prompt: Union[str, List[str]], embedding_model: str) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Retrieves embeddings from OpenAI API for the given prompt using the specified embedding model.\n",
    "\n",
    "    Args:\n",
    "        prompt (Union[str, List[str]]): Input prompt or list of prompts.\n",
    "        embedding_model (str): Name of the embedding model to use.\n",
    "\n",
    "    Returns:\n",
    "        List[List[float]]: List of embeddings for the input prompt(s).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.embeddings.create(\n",
    "            input=prompt if isinstance(prompt, list) else [prompt],\n",
    "            model=embedding_model\n",
    "        )\n",
    "        return [row.embedding for row in response.data]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching embeddings: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f2dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create embeddings for DataFrame\n",
    "def create_embeddings(df: pd.DataFrame, embedding_model: str, batch_size: int) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Creates embeddings for the text data in the DataFrame using the specified embedding model.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing text data.\n",
    "        embedding_model_name (str): Name of the embedding model to use.\n",
    "        batch_size (int): Size of batches for processing.\n",
    "\n",
    "    Returns:\n",
    "        List[List[float]]: List of embeddings corresponding to the text data.\n",
    "    \"\"\"\n",
    "    embeddings_output = []\n",
    "    for idx in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[idx:idx+batch_size]['text'].tolist()\n",
    "        embeddings = get_embeddings(batch, embedding_model)\n",
    "        embeddings_output.extend(embeddings)\n",
    "    return embeddings_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403f543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0   – The 2024 Summer Olympics (French: Les Jeux ...   \n",
      "1   – Paris was awarded the Games at the 131st IO...   \n",
      "2   – Paris 2024 featured the debut of breaking a...   \n",
      "3   – The United States topped the medal table fo...   \n",
      "4   – Despite some controversies throughout relat...   \n",
      "\n",
      "                                           embedding  \n",
      "0  [-0.0023448443971574306, -0.011523667722940445...  \n",
      "1  [-0.014546269550919533, -0.061748284846544266,...  \n",
      "2  [0.03340097889304161, -0.028781693428754807, 0...  \n",
      "3  [0.02059205062687397, 0.015052341856062412, 0....  \n",
      "4  [0.054075319319963455, 0.0010721228318288922, ...  \n"
     ]
    }
   ],
   "source": [
    "df['embedding'] = create_embeddings(df, embedding_model, batch_size)\n",
    "df.to_csv(csv_w_embeddings, sep=',', index=False)\n",
    "\n",
    "# Display DataFrame head\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f904fcb5",
   "metadata": {},
   "source": [
    "## Custom Query Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a765a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build custom context\n",
    "def build_custom_context(question: str, database_df: pd.DataFrame, n: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Builds custom context based on the question and the database DataFrame.\n",
    "\n",
    "    Args:\n",
    "        question (str): The question to include in the prompt.\n",
    "        database_df (pd.DataFrame): The DataFrame containing the database of facts.\n",
    "        n (int): The number of closest facts to include in the context.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of context strings.\n",
    "    \"\"\"\n",
    "    question_embedding = get_embeddings(question, embedding_model)[0]\n",
    "    \n",
    "    df = database_df.copy()\n",
    "    df[\"distances\"] = df['embedding'].apply(lambda embedding: cosine(embedding, question_embedding))\n",
    "\n",
    "    df.sort_values(\"distances\", ascending=True, inplace=True)\n",
    "    return df.iloc[:n]['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4901c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for building the prompt\n",
    "def build_prompt(question: str, csv_path: Optional[str] = None) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Builds a prompt for asking a question, optionally including context from a database DataFrame.\n",
    "\n",
    "    Args:\n",
    "        question (str): The question to include in the prompt.\n",
    "        database_df (Optional[pd.DataFrame]): The DataFrame containing the database of facts. If None, no context is included. Facts are annotated with date and separated by lines.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, str]]: A list containing messages with the user role and optionally a system message with context.\n",
    "    \"\"\"\n",
    "    if csv_path is not None:\n",
    "        # Read the DataFrame from CSV file\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Convert embedding values from string to list of floats\n",
    "        df['embedding'] = df['embedding'].apply(lambda value: [float(dim) for dim in value.replace('[', '').replace(']', '').split(',')])\n",
    "\n",
    "        context = '\\n\\n'.join(build_custom_context(question, df))\n",
    "        return [\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': f\"\"\"\n",
    "                Answer the question based on the context provided. If the question cannot be answered based on provided context, say \"I don't know the answer\".\n",
    "                Context: \n",
    "                    {context}\n",
    "                \"\"\"\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': question\n",
    "            }\n",
    "        ]\n",
    "    else:\n",
    "        return [\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': question\n",
    "            }\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f189a26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_question(question: str, csv_path: Optional[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    Handles a question prompt by generating a response using the specified model.\n",
    "\n",
    "    Args:\n",
    "        prompt (List[Dict[str, str]]): The prompt messages to send to the model.\n",
    "        model_name (str): The name of the completion model to use.\n",
    "\n",
    "    Returns:\n",
    "        str: The response generated by the model.\n",
    "    \"\"\"\n",
    "    prompt = build_prompt(question, csv_path)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=completion_model,\n",
    "        messages=prompt,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration\n",
    "\n",
    "TODO: In the cells below, demonstrate the performance of your custom query using at least 2 questions. For each question, show the answer from a basic `Completion` model query as well as the answer from your custom query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 1: A fact that would have been known prior to 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f646989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer without Context: \n",
      " France, the host country of the 2024 Olympics, last hosted the Olympics in 1924 in Paris.\n",
      "\n",
      "Answer with Context: \n",
      " The host country for the 2024 Olympics, France, last hosted the Olympics in 1924.\n"
     ]
    }
   ],
   "source": [
    "# Example usage using a fact that was likely known prior to 2021\n",
    "question = 'In what year did the host country of the 2024 olympics last host the olympics?'\n",
    "csv_path = './wikipedia_embeddings.csv'\n",
    "\n",
    "\n",
    "# Print answer without context\n",
    "print('Answer without Context: \\n', handle_question(question))\n",
    "\n",
    "# Print answer with context\n",
    "print('\\nAnswer with Context: \\n', handle_question(question, csv_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 2: A fact that would not have been known prior to 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6e0d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer without Context: \n",
      " As of now, the 2024 Paris Olympics have not taken place yet.\n",
      "\n",
      "Answer with Context: \n",
      " The United States and China tied for the most gold medals at the 2024 Paris Olympics, with each country winning 40 gold medals.\n"
     ]
    }
   ],
   "source": [
    "question = 'Which country won the most gold medals at the 2024 Paris Olympics?'\n",
    "csv_path = './wikipedia_embeddings.csv'\n",
    "\n",
    "\n",
    "# Print answer without context\n",
    "print('Answer without Context: \\n', handle_question(question))\n",
    "\n",
    "# Print answer with context\n",
    "print('\\nAnswer with Context: \\n', handle_question(question, csv_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05526d4",
   "metadata": {},
   "source": [
    "### Question 3: A fact that might have been known in 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2b0bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer without Context: \n",
      " The surface-to-air missile system that provided security for the 2024 Paris Olympics was the SAMP/T (Sol-Air Moyenne Portée Terrestre) missile system.\n",
      "\n",
      "Answer with Context: \n",
      " The British Army deployed Starstreak surface-to-air missile units for air security at the 2024 Paris Olympics.\n"
     ]
    }
   ],
   "source": [
    "question = 'What surface-to-air missile system provided security for the 2024 Paris Olympics?'\n",
    "csv_path = './wikipedia_embeddings.csv'\n",
    "\n",
    "\n",
    "# Print answer without context\n",
    "print('Answer without Context: \\n', handle_question(question))\n",
    "\n",
    "# Print answer with context\n",
    "print('\\nAnswer with Context: \\n', handle_question(question, csv_path))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
